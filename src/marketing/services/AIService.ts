import { invoke } from '@tauri-apps/api/core';
import { NeuroContext } from "../types";
import { getContextString } from "./NeuroLibrary";
import { generateAdFromTemplate } from './TemplateEngine';

interface AIResponse {
  text: string | null;
  source: 'Gemini ‚ö° (Cloud)' | 'Groq ‚ö° (Llama 3)' | 'Ollama ü¶ô (Local)' | 'Template JS';
}

export interface AdCopy {
    titles: string;
    descriptions: string;
    negatives: string;
    source: AIResponse['source'];
}

async function callGemini(systemPrompt: string, userPrompt: string) {
  const result = await invoke<{ text: string }>('call_gemini', {
    request: {
      system_prompt: systemPrompt,
      user_prompt: userPrompt,
    },
  });

  if (!result?.text) {
    throw new Error('Gemini returned empty response');
  }

  return {
    text: result.text,
    source: 'Gemini ‚ö° (Cloud)',
  };
}

/**
 * Servi√ßo de Intelig√™ncia Artificial.
 * Encapsula a l√≥gica de chamada de API h√≠brida (Nuvem com Fallback Local).
 */
export class AIService {
  /**
   * Chama o c√©rebro digital (IA) com um prompt de sistema e de usu√°rio.
   * Tenta a API da Groq primeiro e faz fallback para Ollama local.
   */
  private async _callAI(systemPrompt: string, userPrompt: string): Promise<AIResponse> {
    /*
    try {
      // 1Ô∏è‚É£ Gemini (Cloud Principal)
      return await callGemini(systemPrompt, userPrompt);
    } catch (e1) {
      console.warn('Gemini falhou, tentando Ollama', e1);
    */
      try {
        // 2Ô∏è‚É£ Ollama (Local)
        const response = await fetch('http://localhost:11434/api/chat', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            model: "llama3.2:latest",
            messages: [
              { "role": "user", "content": userPrompt }
            ],
            stream: false
          })
        });

        if (!response.ok) {
          throw new Error(`Ollama API error: ${response.status} ${response.statusText}`);
        }
        
        const data = await response.json();
        console.log("Ollama respondeu:", data);
        return { text: data.message.content, source: 'Ollama ü¶ô (Local)' };

      } catch (e2) {
        console.warn('Ollama falhou, usando Template', e2);

        // 3Ô∏è‚É£ Template JS (Fallback Final)
        return generateAdFromTemplate(userPrompt);
      }
    /*
    }
    */
  }

  /**
   * Gera c√≥pia de an√∫ncio (t√≠tulos e descri√ß√µes) para um determinado tema.
   * @param theme O tema do an√∫ncio.
   */
  public async generateAdCopy(theme: string): Promise<AdCopy> {
    const systemPrompt = `ATUE COMO: Estrategista de Marketing Cl√≠nico √âtico (Google PMM). REGRAS: Sem promessas de cura, sem escassez. Foque em valida√ß√£o e acolhimento.`;
    const userPrompt = `Crie 3 t√≠tulos (m√°ximo 30 caracteres cada) e 2 descri√ß√µes (m√°ximo 90 caracteres cada) para um an√∫ncio no Google Ads sobre: ${theme}.`;
    
    const response = await this._callAI(systemPrompt, userPrompt);
    return this._processAdText(response);
  }

  /**
   * Processa o texto bruto da IA e o formata em uma estrutura de AdCopy.
   */
  private _processAdText(response: AIResponse): AdCopy {
    if (!response.text) {
      return { titles: `Terapia para ${'tema'}`, descriptions: 'Atendimento especializado.', negatives: "-gr√°tis", source: response.source };
    }
    
    const lines = response.text.split('\n').filter(l => l.trim().length > 0);
    const titles: string[] = [];
    const descriptions: string[] = [];
    
    lines.forEach(line => {
      const clean = line.replace(/^\d+\.\s*/, '').replace(/["*]/g, '').replace(/t[√≠i]tulo:/i, '').replace(/descri[√ßc][√£a]o:/i, '').trim();
      if (clean.length === 0) return;
      if (clean.length < 50 && titles.length < 3) {
        titles.push(clean);
      } else if (descriptions.length < 2) {
        descriptions.push(clean);
      }
    });

    return {
      titles: titles.join('\n'),
      descriptions: descriptions.join('\n'),
      negatives: "-cura, -r√°pido, -gr√°tis, -imediato",
      source: response.source
    };
  }

  /**
   * Envia uma mensagem do usu√°rio para o S√≥cio Estrat√©gico (IA).
   * @param userMessage A mensagem do usu√°rio.
   * @param contextData O contexto atual do sistema.
   */
  public async sendMessage(userMessage: string, contextData: NeuroContext): Promise<AIResponse> {
    const systemPrompt = this.buildSystemPrompt(contextData);
    return this._callAI(systemPrompt, userMessage);
  }

  /**
   * Constr√≥i o System Prompt din√¢mico para o S√≥cio Estrat√©gico.
   */
  private buildSystemPrompt(contextData: NeuroContext): string {
    const { visibilidade, interesseReal, alcance } = contextData;
    const dadosDoMomento = `
[DADOS DO MOMENTO]
- Visibilidade (Doctoralia): ${visibilidade.doctoraliaViews} views (${visibilidade.tendencia.direcao === 'up' ? 'üìà' : 'üìâ'} ${visibilidade.tendencia.variacaoPercentual}%)
- Interesse Real: ${interesseReal.topServices.join(', ') || 'Nenhum'}
- Alcance Instagram: ${alcance.instagramReach || 0}
    `.trim();

    const bibliotecaMental = `
[SUA BIBLIOTECA MENTAL (Modelos de Decis√£o)]
${getContextString()}
    `.trim();

    return `
ATUE COMO: S√≥cio Estrat√©gico do Psic√≥logo Victor Lawrence.
TOM DE VOZ: Breve, direto ao ponto, estrat√©gico e baseado nos dados fornecidos.
${dadosDoMomento}
${bibliotecaMental}
OBJETIVO: Responda ao seu s√≥cio (Victor) de forma acion√°vel. Se a visibilidade caiu, sugira a√ß√µes da TOC ou Copy. Se est√° alta, sugira focar em convers√£o e autoridade. Use o tom: "Parceiro, vi que..." ou "Victor, a situa√ß√£o √©...".
    `.trim();
  }
}
